{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33f9a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import t\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.anova import AnovaRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ddb27",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b05e57",
   "metadata": {},
   "source": [
    "There are the assumptions required to use ANOVA:\n",
    "1. ANOVA assumes that the data is normally distributed.  \n",
    "2. The ANOVA also assumes homogeneity of variance, which means that the variance among the groups should be approximately equal. \n",
    "3. ANOVA also assumes that the observations are independent of each other.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. For example:\n",
    "1. Violation of independence: If the observations in one group are dependent on the observations in another group, it can lead to biased results.\n",
    "2. Violation of normality: If the data in one or more groups do not follow a normal distribution, it can lead to inaccurate results. \n",
    "3. Violation of homogeneity of variance: If the variance of the data in one or more groups is significantly different from the variance in other groups, it can lead to incorrect conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a3a9d",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44454e5",
   "metadata": {},
   "source": [
    "There are three types of ANOVA test:\n",
    "1. One-Way ANOVA | Complete Randomized Design : This is used when there is only one independent variable (factor) with three or more levels (groups). It is used to test whether there is a significant difference between the means of the groups.\n",
    "\n",
    "2. Two-Way ANOVA | Factirial ANOVA : This is used when there are two independent variables (factors) and one dependent variable. It is used to test whether there is a significant interaction between the two independent variables and the dependent variable. For example, if we want to test the effect of two different treatments on a group of patients and whether the effect depends on the gender of the patients, we can use a two-way ANOVA.\n",
    "\n",
    "3. Repeated measures ANOVA test: In this ANOVA test, you take sample means from at least three different sets of test statistics and compare them against one another. This way, you can look for any key and critical values and notate their statistical significance level as well. You do so primarily through utilizing repeated F-tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0004a3c",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c38cee",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the division of the total variance in the data into different components based on the sources of variation. There are two main sources of variation in ANOVA: \n",
    "1. the variation between groups \n",
    "2. the variation within groups\n",
    "\n",
    "The partitioning of variance helps to determine the relative contribution of each source of variation to the total variance in the data.\n",
    "\n",
    "The total variance in the data can be represented as the sum of squares total (SST), which is calculated as the sum of the squared differences between each observation and the overall mean. The SST can then be partitioned into two components: the sum of squares between (SSB) and the sum of squares within (SSW). The SSB represents the variation between groups, while the SSW represents the variation within groups.\n",
    "\n",
    "The partitioning of variance is important because it allows us to determine whether there is a significant difference between the means of the groups. If the SSB is much larger than the SSW, it suggests that there is a significant difference between the means of the groups. On the other hand, if the SSW is much larger than the SSB, it suggests that there is no significant difference between the means of the groups.\n",
    "\n",
    "Understanding the partitioning of variance is also important because it helps to identify potential sources of error in the study design or data collection process. For example, if there is a large amount of variation within groups, it may indicate that there is a problem with the measurement instrument or that there are confounding variables that need to be controlled for in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9debbbf",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08a5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_way_anova(data):\n",
    "    \"\"\"\n",
    "    Calculates the total sum of squares (SST), sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA.\n",
    "\n",
    "    Args:\n",
    "    data: A list of lists, where each inner list contains the data for one group.\n",
    "\n",
    "    Returns:\n",
    "    A tuple of (SST, SSE, SSR).\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "\n",
    "    # Calculate the total sum of squares\n",
    "    SST = np.sum((data - mean)**2)\n",
    "\n",
    "    # Calculate the explained sum of squares\n",
    "    SSE = 0\n",
    "    for group in data:\n",
    "        group_mean = np.mean(group)\n",
    "        SSE += np.sum((group - group_mean)**2)\n",
    "\n",
    "    # Calculate the residual sum of squares\n",
    "    SSR = SST - SSE\n",
    "\n",
    "    return SST, SSE, SSR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a90f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 60.0\n",
      "SSE: 6.0\n",
      "SSR: 54.0\n"
     ]
    }
   ],
   "source": [
    " # Generate some data\n",
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# Calculate the ANOVA\n",
    "SST, SSE, SSR = one_way_anova(data)\n",
    "\n",
    "# Print the results\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989f216",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da5f51ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         sum_sq   df          F   PR(>F)\n",
      "C(factor_a)                32.0  1.0  21.333333  0.00989\n",
      "C(factor_b)                 2.0  1.0   1.333333  0.31250\n",
      "C(factor_a):C(factor_b)     2.0  1.0   1.333333  0.31250\n",
      "Residual                    6.0  4.0        NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataframe\n",
    "data = pd.DataFrame({\n",
    "    'factor_a': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B'],\n",
    "    'factor_b': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "    'y': [10, 12, 8, 9, 11, 13, 7, 6]\n",
    "})\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('y ~ C(factor_a) + C(factor_b) + C(factor_a):C(factor_b)', data=data).fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(sm.stats.anova_lm(model, typ=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe858317",
   "metadata": {},
   "source": [
    "Main effect of factor_a: The sum of squares for factor_a is 32.0 with 1 degree of freedom, which results in an F-statistic of 21.333 and a p-value of 0.00989. This indicates that there is a significant main effect of factor_a.\n",
    "\n",
    "Main effect of factor_b: The sum of squares for factor_b is 2.0 with 1 degree of freedom, which results in an F-statistic of 1.333 and a p-value of 0.31250. This indicates that there is no significant main effect of factor_b.\n",
    "\n",
    "Interaction effect between factor_a and factor_b: The sum of squares for the interaction between factor_a and factor_b is 2.0 with 1 degree of freedom, which results in an F-statistic of 1.333 and a p-value of 0.31250. This indicates that there is no significant interaction effect between factor_a and factor_b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6b911",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results? \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58518869",
   "metadata": {},
   "source": [
    "If the alpha value is 0.05 and the p-value is 0.02, then we can REJECT the null hypothesis at the 0.05 level of significance. This means that there is sufficient evidence to conclude that there is a statistically significant difference between the groups.\n",
    "\n",
    "The F-statistic of 5.23 suggests that there is a difference between the groups, and the magnitude of the F-value indicates that the variability between groups is 5.23 times the variability within groups. However, post-hoc tests or further analyses are necessary to determine which groups are significantly different from each other.\n",
    "\n",
    "Post Hoc methods like Tukey's Honestly Significant Difference (HSD), Bonferroni correction, Scheffe's method can be used for further analysis of means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4828ab4",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5905333",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, missing data can be handled through different methods, such as pairwise deletion, listwise deletion, or imputation.\n",
    "\n",
    "Pairwise deletion involves analyzing only the available data for each pair of variables, which can lead to a loss of statistical power and biased estimates. Listwise deletion involves analyzing only the cases with complete data, which can lead to a loss of information and reduced sample size. Imputation involves estimating the missing values based on the available data, which can lead to biased estimates if the imputation model is misspecified.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data are that the results of the analysis may differ depending on the method used. Therefore, it is important to carefully consider the missing data mechanism and choose an appropriate method to handle missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e927706",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fcf8df",
   "metadata": {},
   "source": [
    "There are several post-hoc tests that can be used after ANOVA, including Tukey's HSD, Bonferroni correction, Scheffe's method, and Dunnett's test.\n",
    "\n",
    "* Tukey's HSD is commonly used when comparing all possible pairs of means to determine which pairs are significantly different from each other. \n",
    "* Bonferroni correction is used to control for Type I error rate when multiple comparisons are made. \n",
    "* Scheffe's method is used when there are multiple hypotheses being tested at once. \n",
    "* Dunnett's test is used when comparing multiple treatments to a control group.\n",
    "\n",
    "A situation where a post-hoc test might be necessary is when conducting a study with multiple groups and a significant difference is found between the means. A post-hoc test can be used to determine which specific groups have significantly different means from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b376caf",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed74b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 3.4089499921915496\n",
      "p-value: 0.035712362822675564\n",
      "Reject Ho. At least, one mean differ to the other mean\n"
     ]
    }
   ],
   "source": [
    "Ho = \"Three mean belongs to the same population\"\n",
    "Ha = \"At least, one mean differ to the other mean\"\n",
    "\n",
    "A = np.random.normal( 5, 1, 50)\n",
    "B = np.random.normal( 4.5, 1, 50)\n",
    "C = np.random.normal( 4.7, 1, 50)\n",
    "\n",
    "# f test statistic and p value\n",
    "f_stat, p_value = f_oneway( A, B, C )\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value < alpha:\n",
    "    print(\"Reject Ho.\", Ha)\n",
    "else:\n",
    "    print(\"Fail to reject Ho.\", Ho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221e79",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e47eeb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             df      sum_sq     mean_sq          F  \\\n",
      "C(Software)                 2.0  232.569522  116.284761  39.015083   \n",
      "C(Experience)               1.0  245.672030  245.672030  82.426231   \n",
      "C(Software):C(Experience)   2.0    4.160624    2.080312   0.697972   \n",
      "Residual                   86.0  256.323678    2.980508        NaN   \n",
      "\n",
      "                                 PR(>F)  \n",
      "C(Software)                8.744065e-13  \n",
      "C(Experience)              3.399439e-14  \n",
      "C(Software):C(Experience)  5.003897e-01  \n",
      "Residual                            NaN  \n"
     ]
    }
   ],
   "source": [
    "# Generating 2 random time samples for novice and expert\n",
    "time_novice = np.random.normal(loc=15, scale=2, size=45)\n",
    "time_expert = np.random.normal(loc=10, scale=2, size=45)\n",
    "\n",
    "# Generate simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "    'Experience': ['Novice']*45 + ['Experienced']*45,\n",
    "    'Time': list(time_novice)+list(time_expert)\n",
    "})\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, type=2)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7114043",
   "metadata": {},
   "source": [
    "* For program, the F-statistic is 39.015 and the p-value is 8.744065e-13, which is much smaller than the significance level of 0.05, indicating that there is a significant difference in the average time it takes to complete the task using different software programs.\n",
    "* For Experience, the F-statistic is 39.015 and the p-value is 8.744065e-13, which is much smaller than the significance level of 0.05, indicating that there is a significant difference in the average time it takes to complete the task using different software programs.\n",
    "* For interaction effect between Program and experience, the F-statistic is 0.698 and the p-value is 0.500, which is much larger than the significance level of 0.05, indicating that there is no significant interaction effect between software program and employee experience level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09344ee3",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15b5e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_stat = 3.335852168325221\n",
      "t crtical 1 = -1.972017477833896\n",
      "t crtical 2 = 1.9720174778338955\n",
      "p value = 0.001015401276676933\n",
      "Reject Ho. There is a significant difference in students score\n"
     ]
    }
   ],
   "source": [
    "Ho = \"There is no difference in students score\"\n",
    "Ha = \"There is a significant difference in students score\"\n",
    "\n",
    "groupA = np.random.normal( loc = 80, scale = 10, size = 100)\n",
    "groupB = np.random.normal( loc = 75, scale = 10, size = 100)\n",
    "\n",
    "#significance value\n",
    "alpha = 0.05\n",
    "\n",
    "#f stat and p value\n",
    "t_stat, p_value = ttest_ind( groupA, groupB)\n",
    "\n",
    "# f critical value \n",
    "t_crit1 = t.ppf( alpha/2, 198)\n",
    "t_crit2 = t.ppf( 1-alpha/2, 198)\n",
    "\n",
    "print(f\"t_stat = {t_stat}\")\n",
    "print(f\"t crtical 1 = {t_crit1}\")\n",
    "print(f\"t crtical 2 = {t_crit2}\")\n",
    "print(f\"p value = {p_value}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject Ho.\", Ha)\n",
    "else:\n",
    "    print(\"Fail to reject Ho.\", Ho)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2661af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Post-hoc Tukey's HSD test results:\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------\n",
      "     A      B  -4.6196 0.001 -7.3505 -1.8887   True\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    " # Combine the two groups of test scores into one array\n",
    "all_scores = np.concatenate((groupA, groupB))\n",
    "\n",
    "# Create a list of group labels corresponding to each score in the combined array\n",
    "group_labels = ['A'] * len(groupA) + ['B'] * len(groupB)\n",
    "\n",
    "# Conduct a post-hoc Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(all_scores, group_labels)\n",
    "\n",
    "# Print the post-hoc results\n",
    "print(\"\\nPost-hoc Tukey's HSD test results:\")\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996520f",
   "metadata": {},
   "source": [
    "Based on the post-hoc Tukey's HSD test results, there is a statistically significant difference in test scores between group A and group B. The mean test score for group B is significantly lower (mean difference of -4.6196) compared to group A.\n",
    "\n",
    "With a p-value of 0.001 (p-adj), which is less than the significance level of 0.05, we can reject the null hypothesis that there is no difference in test scores between the two groups. Therefore, we have evidence to suggest that the new teaching method (group A) has a significant impact on improving student test scores compared to the traditional teaching method (group B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603489b",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a posthoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15243701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store A</th>\n",
       "      <th>Store B</th>\n",
       "      <th>Store C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555.948914</td>\n",
       "      <td>705.129859</td>\n",
       "      <td>570.691259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>537.873554</td>\n",
       "      <td>706.762923</td>\n",
       "      <td>699.211108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>553.648378</td>\n",
       "      <td>599.053916</td>\n",
       "      <td>674.404570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>501.773959</td>\n",
       "      <td>724.606701</td>\n",
       "      <td>520.446802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589.422214</td>\n",
       "      <td>666.055742</td>\n",
       "      <td>564.243875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>482.359056</td>\n",
       "      <td>641.970916</td>\n",
       "      <td>545.581010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>441.689131</td>\n",
       "      <td>640.131157</td>\n",
       "      <td>663.249186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>580.681406</td>\n",
       "      <td>637.584827</td>\n",
       "      <td>551.160223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>526.154582</td>\n",
       "      <td>630.776774</td>\n",
       "      <td>612.341665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>529.558091</td>\n",
       "      <td>670.772723</td>\n",
       "      <td>624.623479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>492.425235</td>\n",
       "      <td>629.246101</td>\n",
       "      <td>570.476559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>527.081558</td>\n",
       "      <td>721.151509</td>\n",
       "      <td>595.775728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>525.587731</td>\n",
       "      <td>654.322780</td>\n",
       "      <td>586.639449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>440.239645</td>\n",
       "      <td>560.107489</td>\n",
       "      <td>711.413246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>508.063630</td>\n",
       "      <td>780.727012</td>\n",
       "      <td>631.989691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>498.292479</td>\n",
       "      <td>702.576217</td>\n",
       "      <td>599.101643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>512.427520</td>\n",
       "      <td>663.390692</td>\n",
       "      <td>504.448051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>553.688166</td>\n",
       "      <td>616.782461</td>\n",
       "      <td>565.615871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>404.783523</td>\n",
       "      <td>720.828533</td>\n",
       "      <td>588.579322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>533.501177</td>\n",
       "      <td>576.251125</td>\n",
       "      <td>561.908690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>518.972365</td>\n",
       "      <td>631.939103</td>\n",
       "      <td>671.327997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>540.704647</td>\n",
       "      <td>714.040686</td>\n",
       "      <td>609.268279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>510.031568</td>\n",
       "      <td>568.109334</td>\n",
       "      <td>736.925948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>573.903610</td>\n",
       "      <td>513.601242</td>\n",
       "      <td>563.597697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>452.793975</td>\n",
       "      <td>748.423515</td>\n",
       "      <td>604.138390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>482.424353</td>\n",
       "      <td>648.689059</td>\n",
       "      <td>698.632080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>466.357150</td>\n",
       "      <td>619.247278</td>\n",
       "      <td>598.151024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>526.155306</td>\n",
       "      <td>601.972941</td>\n",
       "      <td>562.883008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>472.727634</td>\n",
       "      <td>695.373768</td>\n",
       "      <td>641.778496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>501.410701</td>\n",
       "      <td>707.688480</td>\n",
       "      <td>511.605312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store A     Store B     Store C\n",
       "0   555.948914  705.129859  570.691259\n",
       "1   537.873554  706.762923  699.211108\n",
       "2   553.648378  599.053916  674.404570\n",
       "3   501.773959  724.606701  520.446802\n",
       "4   589.422214  666.055742  564.243875\n",
       "5   482.359056  641.970916  545.581010\n",
       "6   441.689131  640.131157  663.249186\n",
       "7   580.681406  637.584827  551.160223\n",
       "8   526.154582  630.776774  612.341665\n",
       "9   529.558091  670.772723  624.623479\n",
       "10  492.425235  629.246101  570.476559\n",
       "11  527.081558  721.151509  595.775728\n",
       "12  525.587731  654.322780  586.639449\n",
       "13  440.239645  560.107489  711.413246\n",
       "14  508.063630  780.727012  631.989691\n",
       "15  498.292479  702.576217  599.101643\n",
       "16  512.427520  663.390692  504.448051\n",
       "17  553.688166  616.782461  565.615871\n",
       "18  404.783523  720.828533  588.579322\n",
       "19  533.501177  576.251125  561.908690\n",
       "20  518.972365  631.939103  671.327997\n",
       "21  540.704647  714.040686  609.268279\n",
       "22  510.031568  568.109334  736.925948\n",
       "23  573.903610  513.601242  563.597697\n",
       "24  452.793975  748.423515  604.138390\n",
       "25  482.424353  648.689059  698.632080\n",
       "26  466.357150  619.247278  598.151024\n",
       "27  526.155306  601.972941  562.883008\n",
       "28  472.727634  695.373768  641.778496\n",
       "29  501.410701  707.688480  511.605312"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sales data for Store A, B, and C\n",
    "sales_a = np.random.normal(loc=500, scale=50, size=(30,))\n",
    "sales_b = np.random.normal(loc=650, scale=60, size=(30,))\n",
    "sales_c = np.random.normal(loc=600, scale=55, size=(30,))\n",
    "\n",
    "# create a DataFrame\n",
    "sales_df = pd.DataFrame({'Store A': sales_a, 'Store B': sales_b, 'Store C': sales_c})\n",
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "860f2009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store 44.2664 2.0000 58.0000 0.0000\n",
      "===================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reshape the DataFrame for repeated measures ANOVA\n",
    "sales_melted = pd.melt(sales_df.reset_index( names = \"Day\" ), id_vars=['Day'], value_vars=['Store A', 'Store B', 'Store C'], var_name = \"Store\", value_name = \"Sales\")\n",
    "rm_anova = AnovaRM(sales_melted, 'Sales', 'Day', within=['Store'])\n",
    "rm_results = rm_anova.fit()\n",
    "print(rm_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03fe2488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the Null Hypothesis : Atleast one of the group has different mean.\n",
      "\n",
      "Tukey HSD posthoc test:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1  group2 meandiff p-adj   lower    upper   reject\n",
      "--------------------------------------------------------\n",
      "Store A Store B 145.2211    0.0 111.0682  179.374   True\n",
      "Store A Store C  93.3176    0.0  59.1647 127.4705   True\n",
      "Store B Store C -51.9035 0.0014 -86.0564 -17.7506   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check if null hypothesis should be rejected based on p-value\n",
    "if rm_results.anova_table['Pr > F'][0] < 0.05:\n",
    "    # perform post-hoc Tukey test\n",
    "    print('Reject the Null Hypothesis : Atleast one of the group has different mean.\\n')\n",
    "    print('Tukey HSD posthoc test:')\n",
    "    tukey_results = pairwise_tukeyhsd(sales_melted['Sales'], sales_melted['Store'])\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print('NO significant difference between groups.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
