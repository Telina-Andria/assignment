{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152b33ff",
   "metadata": {},
   "source": [
    "# Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eeb87f",
   "metadata": {},
   "source": [
    "Lasso Regression is a regularization technique frequently used in linear regression models for feature selection. It achieves this by adding a penalty term to the cost function, which forces features that are weakly correlated with the dependent variable to be set to zero. This helps to simplify the model and avoid overfitting, resulting in better generalization performance.\n",
    "\n",
    "The mathematical formula for lasso regression is:\n",
    "\n",
    "$\n",
    "min β ||y - Xβ||^2_2 + α ||β||_1\n",
    "$\n",
    "where:\n",
    "\n",
    "* β is the vector of coefficients\n",
    "* y is the vector of target values\n",
    "* X is the matrix of feature values\n",
    "* $||⋅||_2$ is the L2 norm\n",
    "* $||⋅||_1$ is the L1 norm\n",
    "* α is a hyperparameter that controls the strength of the regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f66d6a2",
   "metadata": {},
   "source": [
    "# Q2. What is the main advantage of using Lasso Regression in feature selection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fa886",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression in feature selection is that it can effectively reduce the number of features in the model by setting the coefficients of irrelevant or redundant features to zero. This results in a simpler model ,less prone to overfitting, and can potentially improve the generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefea5ee",
   "metadata": {},
   "source": [
    "# Q3. How do you interpret the coefficients of a Lasso Regression model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9150b",
   "metadata": {},
   "source": [
    "The coefficients of the model represent the strength and direction of the relationship between each feature and the dependent variable. A positive coefficient indicates a positive correlation and a negative coefficient indicates a negative correlation.\n",
    "\n",
    "The magnitude of the coefficient reflects the importance of the corresponding feature in predicting the target variable. Larger coefficients indicate stronger relationships and more influential features, while smaller coefficients indicate weaker relationships and less important features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a19bbd1",
   "metadata": {},
   "source": [
    "# Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6def0",
   "metadata": {},
   "source": [
    "The tuning parameter in lasso regression is λ, which controls the strength of the regularization. As λ increases, more and more coefficients are set to zero. This means that lasso regression can be used for feature selection, as well as regression.\n",
    "\n",
    "The following table shows how the tuning parameter λ affects the model's performance:\n",
    "\n",
    "| λ | Model performance |\n",
    "|---|---|\n",
    "| Low | Model is overfit, with high variance and low bias. |\n",
    "| Medium | Model is well-fit, with good bias and variance. |\n",
    "| High | Model is underfit, with low variance and high bias. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0415962",
   "metadata": {},
   "source": [
    "# Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2b378",
   "metadata": {},
   "source": [
    "Yes, lasso regression can be used for non-linear regression problems. One way to do this is to use basis functions. Basis functions are mathematical functions that can be used to represent non-linear relationships. For example, a common basis function is the polynomial function.\n",
    "\n",
    "Another way to use lasso regression for non-linear regression is to use a nonlinear activation function in the model. For example, a common nonlinear activation function is the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6099ba",
   "metadata": {},
   "source": [
    "# Q6. What is the difference between Ridge Regression and Lasso Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2ca57e",
   "metadata": {},
   "source": [
    "Ridge regression and lasso regression are both regularization techniques that can be used to improve the performance of linear regression models. Regularization works by adding a penalty term to the cost function, which encourages the model to shrink the coefficients of the features towards zero.\n",
    "\n",
    "The main difference between ridge regression and lasso regression is the type of penalty term that is used. Ridge regression uses an L2 penalty term, while lasso regression uses an L1 penalty term.\n",
    "\n",
    "Also Ridge regression is widely used for datasets containing multicollinearity, while lasso regression is often used for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7df59",
   "metadata": {},
   "source": [
    "# Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35203aa9",
   "metadata": {},
   "source": [
    " Yes, lasso regression can handle multicollinearity in the input features. Lasso regression works by shrinking the coefficients of the features towards zero, and it may set some of the coefficients to zero completely. This can help to reduce the effects of multicollinearity, as it can force the model to choose one of the correlated features over the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c6daf",
   "metadata": {},
   "source": [
    "# Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb31b7",
   "metadata": {},
   "source": [
    "There are two main methods for choosing the optimal value of the regularization parameter (λ) in lasso regression:\n",
    "\n",
    "* Grid search: This involves trying a range of different values of λ and evaluating the model performance on a held-out validation set. The value of λ that produces the best performance on the validation set is selected as the optimal value.\n",
    "* Cross-validation: This involves dividing the training data into a number of folds, and then training the model and evaluating its performance on each fold. The value of λ that produces the best average performance across all folds is selected as the optimal value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
